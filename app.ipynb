{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Laboratorio 7 - HMM y CRF con dataset real de NER en español\n",
    "Francisco Castillo - 21562"
   ],
   "id": "fc01845437a5008a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ejercicio 1 - HMM:",
   "id": "5d92de19e6d5d5ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### a) Instala e importa el dataset",
   "id": "efbcec7d1a208cac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:27.974302Z",
     "start_time": "2025-09-03T04:27:25.391327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"IEETA/SPACCC-Spanish-NER\")"
   ],
   "id": "35244f0b601376b3",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### b) Explora el dataset",
   "id": "cde839be0da80ecf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:28.005298Z",
     "start_time": "2025-09-03T04:27:27.984298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train, test = dataset[\"train\"], dataset[\"test\"]\n",
    "print(f\"Train size: {len(train)}\")\n",
    "print(f\"Test size: {len(test)}\")"
   ],
   "id": "4b15ac7f7fb54f6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 33757\n",
      "Test size: 11239\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:28.192278Z",
     "start_time": "2025-09-03T04:27:28.180279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(train[:5])"
   ],
   "id": "d45642588fd69238",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ann_id': [0, 1, 2, 3, 4],\n",
      " 'end_span': [73, 190, 278, 230, 305],\n",
      " 'filename': ['S0004-06142005000500011-1',\n",
      "              'S0004-06142005000500011-1',\n",
      "              'S0004-06142005000500011-1',\n",
      "              'S0004-06142005000500011-1',\n",
      "              'S0004-06142005000500011-1'],\n",
      " 'label': ['DISEASE', 'DISEASE', 'PROCEDURE', 'DISEASE', 'DISEASE'],\n",
      " 'start_span': [50, 158, 192, 207, 280],\n",
      " 'text': ['alergias medicamentosas',\n",
      "          'fracturas vertebrales y costales',\n",
      "          'intervenido de enfermedad de Dupuytren en mano derecha y by-pass '\n",
      "          'iliofemoral izquierdo',\n",
      "          'enfermedad de Dupuytren',\n",
      "          'Diabetes Mellitus tipo II']}\n"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "El dataset no contiene etiquetas BIO predeterminadas, por lo que procedemos a crearlas manualmente. Es de notar que e `text` no se encuentra dentro de un corpus de texto, por lo que no hay palabras que no pertenezcan a una entidad nombrada; es decir, todas las palabras deben ser etiquetadas como parte de una entidad nombrada (B-XXX o I-XXX).",
   "id": "993ff12aad921165"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### c) Preprocesamiento",
   "id": "846db992e78aab40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creación de etiquetas BIO",
   "id": "797b0d772b83a31a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:28.284937Z",
     "start_time": "2025-09-03T04:27:28.271938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_bio_labels(text, label):\n",
    "    return [f\"B-{label}\"] + [f\"I-{label}\"] * (len(text.split()) - 1)"
   ],
   "id": "cb1a79a585ba9957",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:31.963631Z",
     "start_time": "2025-09-03T04:27:28.290937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bio_tags = set()\n",
    "for split in dataset.keys():\n",
    "    for example in dataset[split]:\n",
    "        bio_tags.update(create_bio_labels(example[\"text\"], example[\"label\"]))\n",
    "bio_tags = sorted(bio_tags)  # sorted list of unique BIO tags\n",
    "bio_tags = {tag: idx for idx, tag in enumerate(bio_tags)}  # mapping to integers"
   ],
   "id": "e75d0aaa717bd3d9",
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:32.040278Z",
     "start_time": "2025-09-03T04:27:32.026726Z"
    }
   },
   "cell_type": "code",
   "source": "bio_tags",
   "id": "a6ca949ea97b518e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-CHEMICAL': 0,\n",
       " 'B-DISEASE': 1,\n",
       " 'B-PROCEDURE': 2,\n",
       " 'B-PROTEIN': 3,\n",
       " 'B-SYMPTOM': 4,\n",
       " 'I-CHEMICAL': 5,\n",
       " 'I-DISEASE': 6,\n",
       " 'I-PROCEDURE': 7,\n",
       " 'I-PROTEIN': 8,\n",
       " 'I-SYMPTOM': 9}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Mapear cada token y etiqueta a un número entero",
   "id": "768367d83d43ebc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:35.062976Z",
     "start_time": "2025-09-03T04:27:32.105260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_words = list(train) + list(test)\n",
    "all_word =  sorted(set(\n",
    "    word\n",
    "    for example in all_words\n",
    "    for word in example[\"text\"].split()\n",
    "))\n",
    "word2idx = {word: idx for idx, word in enumerate(sorted(all_word))}"
   ],
   "id": "a2d5d6932e124b2e",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:35.141844Z",
     "start_time": "2025-09-03T04:27:35.129253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_numbers(observation):\n",
    "    text = observation[\"text\"]\n",
    "    label = observation[\"label\"]\n",
    "    return{\n",
    "        \"tokens\": [word2idx[word] for word in text.split()],\n",
    "        \"bio_labels\": [bio_tags[tag] for tag in create_bio_labels(text, label)]\n",
    "    }"
   ],
   "id": "79726d36b38d8cc8",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:35.406375Z",
     "start_time": "2025-09-03T04:27:35.205815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = train.map(lambda x: get_numbers(x))\n",
    "test = test.map(lambda x: get_numbers(x))"
   ],
   "id": "ea992bfc07492456",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:35.485318Z",
     "start_time": "2025-09-03T04:27:35.472356Z"
    }
   },
   "cell_type": "code",
   "source": "train[0]",
   "id": "419f04ef9deb34e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'S0004-06142005000500011-1',\n",
       " 'ann_id': 0,\n",
       " 'label': 'DISEASE',\n",
       " 'start_span': 50,\n",
       " 'end_span': 73,\n",
       " 'text': 'alergias medicamentosas',\n",
       " 'tokens': [4195, 12111],\n",
       " 'bio_labels': [1, 6]}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 191
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### d) Calculo de Marices",
   "id": "8279f6e2a2158c35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:38.450199Z",
     "start_time": "2025-09-03T04:27:35.551081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "n_tags = len(bio_tags)\n",
    "n_words = len(word2idx)\n",
    "\n",
    "# Initialize matrices\n",
    "transition_counts = np.zeros((n_tags, n_tags), dtype=int)\n",
    "emission_counts = np.zeros((n_tags, n_words), dtype=int)\n",
    "\n",
    "# Count transitions and emissions\n",
    "for example in train:\n",
    "    labels = example[\"bio_labels\"]\n",
    "    tokens = example[\"tokens\"]\n",
    "    for i in range(len(labels)):\n",
    "        emission_counts[labels[i], tokens[i]] += 1\n",
    "        if i > 0:\n",
    "            transition_counts[labels[i-1], labels[i]] += 1\n",
    "\n",
    "# Normalize to get probabilities\n",
    "transition_matrix = transition_counts / transition_counts.sum(axis=1, keepdims=True)\n",
    "emission_matrix = emission_counts / emission_counts.sum(axis=1, keepdims=True)"
   ],
   "id": "5df4b591dfc3d0",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:38.528523Z",
     "start_time": "2025-09-03T04:27:38.514442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Handle NaN values (rows that sum to zero)\n",
    "transition_matrix = np.nan_to_num(transition_matrix)\n",
    "emission_matrix = np.nan_to_num(emission_matrix)"
   ],
   "id": "6cf8c91d980f5f0e",
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:38.605486Z",
     "start_time": "2025-09-03T04:27:38.591492Z"
    }
   },
   "cell_type": "code",
   "source": "transition_matrix",
   "id": "126f71f8d28f608b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:38.745571Z",
     "start_time": "2025-09-03T04:27:38.732112Z"
    }
   },
   "cell_type": "code",
   "source": "emission_matrix.shape",
   "id": "a21c0b3fc18ccb83",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 17838)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### e) HMM Multinomial",
   "id": "89077590106fe02c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:38.824583Z",
     "start_time": "2025-09-03T04:27:38.810560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from hmmlearn.hmm import CategoricalHMM"
   ],
   "id": "eb4b9716597a518b",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:38.856177Z",
     "start_time": "2025-09-03T04:27:38.844178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "idx2tag = {v: k for k, v in bio_tags.items()}\n",
    "idx2word = {v: k for k, v in word2idx.items()}"
   ],
   "id": "77b2b81b7f6ea77b",
   "outputs": [],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:38.935318Z",
     "start_time": "2025-09-03T04:27:38.923308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper: pack sequences into hmmlearn's expected shape\n",
    "def pack_sequences(ds, key=\"tokens\"):\n",
    "    lengths = [len(ex[key]) for ex in ds]\n",
    "    X = np.concatenate([np.asarray(ex[key], dtype=int).reshape(-1, 1) for ex in ds], axis=0)\n",
    "    return X, lengths"
   ],
   "id": "8b532d8654df3845",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:41.778842Z",
     "start_time": "2025-09-03T04:27:38.998991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute start probabilities from first labels in each sequence\n",
    "n_tags = len(bio_tags)\n",
    "n_words = len(word2idx)\n",
    "start_counts = np.zeros(n_tags, dtype=float)\n",
    "for ex in train:\n",
    "    if len(ex[\"bio_labels\"]) > 0:\n",
    "        start_counts[ex[\"bio_labels\"][0]] += 1.0"
   ],
   "id": "16989ce3e1afe60b",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:41.872391Z",
     "start_time": "2025-09-03T04:27:41.859351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Laplace smoothing and normalization\n",
    "eps = 1e-8\n",
    "startprob = start_counts + eps\n",
    "startprob = startprob / startprob.sum()\n",
    "\n",
    "# (transition_counts: [n_tags, n_tags], emission_counts: [n_tags, n_words])\n",
    "transmat = transition_counts.astype(float) + eps\n",
    "transmat = transmat / np.clip(transmat.sum(axis=1, keepdims=True), 1.0, None)\n",
    "\n",
    "emissionprob = emission_counts.astype(float) + eps\n",
    "emissionprob = emissionprob / np.clip(emissionprob.sum(axis=1, keepdims=True), 1.0, None)"
   ],
   "id": "63c367a0573b6372",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:48.458861Z",
     "start_time": "2025-09-03T04:27:41.953910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, lengths_train = pack_sequences(train)\n",
    "\n",
    "model = CategoricalHMM(\n",
    "    n_components=n_tags,\n",
    "    init_params=\"\",  # do not overwrite our params\n",
    "    params=\"\",       # do not update during fit\n",
    "    random_state=0\n",
    ")\n",
    "model.n_features = n_words\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.emissionprob_ = emissionprob"
   ],
   "id": "49a07c52e1ee76ff",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### f) Decodificación con Viterbi",
   "id": "619aa814c297f790"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T04:27:53.028359Z",
     "start_time": "2025-09-03T04:27:48.524873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_correct = 0\n",
    "all_total = 0\n",
    "for ex in test:\n",
    "    obs = np.asarray(ex[\"tokens\"], dtype=int).reshape(-1, 1)\n",
    "    y_pred = model.predict(obs)\n",
    "    y_true = np.asarray(ex[\"bio_labels\"], dtype=int)\n",
    "    all_correct += (y_pred == y_true).sum()\n",
    "    all_total += len(y_true)\n",
    "\n",
    "print(\"Token accuracy (test set): {:.3f}\".format(all_correct / max(all_total, 1)))"
   ],
   "id": "23f33eea0db8e316",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token accuracy (test set): 0.811\n"
     ]
    }
   ],
   "execution_count": 202
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reflexiona\n",
    "#### ¿Cómo afecta la diversidad de datos a las matrices?\n",
    "\n",
    "La diversidad de los datos influye directamente en las matrices de transición y emisión del HMM. Si algunas palabras o etiquetas aparecen muy pocas veces, las probabilidades estimadas para esas combinaciones serán muy bajas o incluso cero, lo que puede llevar al modelo a favorecer etiquetas frecuentes y a ignorar secuencias poco representadas. Además, la diversidad limitada puede causar que ciertas transiciones nunca se observen en el entrenamiento, generando huecos en la matriz de transición que afectan la capacidad del HMM para generalizar a nuevos ejemplos.\n",
    "\n",
    "En este caso, hemos mencionado que no existen etiquetas `O` en el dataset, lo que significa que todas las palabras deben ser etiquetadas como parte de una entidad nombrada. Esto puede llevar a que el modelo tenga dificultades para manejar palabras que no pertenecen a ninguna entidad en un contexto real, ya que no ha aprendido a reconocerlas. La falta de diversidad en las etiquetas puede limitar la capacidad del modelo para adaptarse a situaciones del mundo real donde no todas las palabras son parte de entidades nombradas.\n",
    "\n",
    "---\n",
    "\n",
    "#### ¿Qué etiquetas o palabras presentan probabilidades bajas o cero y cómo podría resolverse?\n",
    "\n",
    "Las palabras raras o únicas en el dataset, así como etiquetas poco frecuentes, tienden a tener emisiones o transiciones con probabilidades muy bajas o cero. Esto incluye nombres propios poco comunes, errores tipográficos o entidades que aparecen solo en unos pocos ejemplos. Además, palabras que aparecen en el test pero no en el entrenamiento (`OOV`) no tendrán representación en la matriz de emisión, lo que puede generar predicciones incorrectas o ceros. Esto, pues creamos un token para todas las palabras en el dataset (tanto train como test).\n",
    "\n",
    "Para resolverlo, se puede aplicar Laplace Smoothing para evitar probabilidades nulas, introducir un token `<UNK>` para palabras desconocidas, agrupar etiquetas muy poco frecuentes en categorías generales y aumentar ejemplos de entidades raras. Además de, obviamente, incluir palabras con la etiqueta `O` en el dataset para que el modelo pueda aprender a manejarlas.\n",
    "\n"
   ],
   "id": "af74198bcfd9da0a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
